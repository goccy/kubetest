//go:build !ignore_autogenerated
// +build !ignore_autogenerated

package v1

import (
	"context"
	"fmt"
	"os"
	"os/exec"
	"path/filepath"
	"strings"
	"time"

	"github.com/goccy/kubejob"
	batchv1 "k8s.io/api/batch/v1"
	corev1 "k8s.io/api/core/v1"
	"k8s.io/client-go/rest"
)

type PreInitCallback func(context.Context, JobExecutor) error

type Job interface {
	Spec() batchv1.JobSpec
	PreInit(TestJobContainer, PreInitCallback)
	RunWithExecutionHandler(context.Context, func([]JobExecutor) error) error
	Mount(func(ctx context.Context, exec JobExecutor, isInitContainer bool) error)
}

type JobExecutor interface {
	Output(context.Context) ([]byte, error)
	ExecAsync(context.Context)
	TerminationLog(context.Context, string) error
	Stop(context.Context) error
	CopyFrom(context.Context, string, string) error
	CopyTo(context.Context, string, string) error
	Container() corev1.Container
	Pod() *corev1.Pod
	PrepareCommand([]string) ([]byte, error)
}

type JobBuilder struct {
	cfg       *rest.Config
	namespace string
	runMode   RunMode
}

func NewJobBuilder(cfg *rest.Config, namespace string, runMode RunMode) *JobBuilder {
	return &JobBuilder{
		cfg:       cfg,
		namespace: namespace,
		runMode:   runMode,
	}
}

func (b *JobBuilder) BuildWithJob(jobSpec *batchv1.Job, containerNameToInstalledPathMap map[string]string, sharedAgentSpec *TestAgentSpec) (Job, error) {
	switch b.runMode {
	case RunModeKubernetes:
		job, err := kubejob.NewJobBuilder(b.cfg, b.namespace).BuildWithJob(jobSpec)
		if err != nil {
			return nil, err
		}
		var agentConfig *kubejob.AgentConfig
		if sharedAgentSpec != nil {
			cfg, err := kubejob.NewAgentConfig(containerNameToInstalledPathMap)
			if err != nil {
				return nil, fmt.Errorf("kubetest: failed to create agent config: %w", err)
			}
			if sharedAgentSpec.AllocationStartPort != nil {
				cfg.SetAllocationStartPort(*sharedAgentSpec.AllocationStartPort)
			}
			if len(sharedAgentSpec.ExcludePorts) != 0 {
				cfg.SetExcludePorts(sharedAgentSpec.ExcludePorts...)
			}
			job.UseAgent(cfg)
			agentConfig = cfg
		}
		return newKubernetesJob(job, agentConfig), nil
	case RunModeLocal:
		rootDir, err := os.MkdirTemp("", "root")
		if err != nil {
			return nil, fmt.Errorf("kubetest: failed to create working directory for running on local file system")
		}
		return newLocalJob(rootDir, jobSpec), nil
	case RunModeDryRun:
		return &dryRunJob{job: jobSpec}, nil
	}
	return nil, fmt.Errorf("kubetest: unknown run mode %v", b.runMode)
}

type kubernetesJob struct {
	preInitCallbackContext context.Context
	job                    *kubejob.Job
	agentConfig            *kubejob.AgentConfig
	mountCallback          func(context.Context, JobExecutor, bool) error
}

var defaultMountCallback = func(context.Context, JobExecutor, bool) error { return nil }

func newKubernetesJob(job *kubejob.Job, agentConfig *kubejob.AgentConfig) *kubernetesJob {
	return &kubernetesJob{
		job:           job,
		agentConfig:   agentConfig,
		mountCallback: defaultMountCallback,
	}
}

func (j *kubernetesJob) Spec() batchv1.JobSpec {
	return j.job.Spec
}

func (j *kubernetesJob) PreInit(c TestJobContainer, cb PreInitCallback) {
	j.job.PreInit(c.Container, func(exec *kubejob.JobExecutor) error {
		return cb(j.preInitCallbackContext, &kubernetesJobExecutor{exec: exec})
	})
}

func (j *kubernetesJob) Mount(cb func(context.Context, JobExecutor, bool) error) {
	j.mountCallback = cb
}

func (j *kubernetesJob) RunWithExecutionHandler(ctx context.Context, handler func([]JobExecutor) error) error {
	j.preInitCallbackContext = ctx
	j.job.DisableInitContainerLog()
	j.job.SetPendingPhaseTimeout(10 * time.Minute)
	j.job.SetInitContainerExecutionHandler(func(exec *kubejob.JobExecutor) error {
		e := &kubernetesJobExecutor{exec: exec}
		if err := j.mountCallback(ctx, e, true); err != nil {
			return err
		}
		_, err := exec.ExecOnly()
		return err
	})
	return j.job.RunWithExecutionHandler(ctx, func(execs []*kubejob.JobExecutor) error {
		converted := make([]JobExecutor, 0, len(execs))
		for _, exec := range execs {
			e := &kubernetesJobExecutor{exec: exec}
			if err := j.mountCallback(ctx, e, false); err != nil {
				return err
			}
			converted = append(converted, e)
		}
		return handler(converted)
	})
}

type kubernetesJobExecutor struct {
	exec *kubejob.JobExecutor
}

func (e *kubernetesJobExecutor) PrepareCommand(cmd []string) ([]byte, error) {
	return e.exec.ExecPrepareCommand([]string{"sh", "-c", strings.Join(cmd, " ")})
}

func (e *kubernetesJobExecutor) Output(_ context.Context) ([]byte, error) {
	return e.exec.ExecOnly()
}

func (e *kubernetesJobExecutor) ExecAsync(_ context.Context) {
	e.exec.ExecAsync()
}

func (e *kubernetesJobExecutor) TerminationLog(_ context.Context, log string) error {
	return e.exec.TerminationLog(log)
}

func (e *kubernetesJobExecutor) Stop(_ context.Context) error {
	return e.exec.Stop()
}

func (e *kubernetesJobExecutor) execProtocol() string {
	if e.exec.EnabledAgent() {
		return "grpc"
	}
	return "k8s-api"
}

func (e *kubernetesJobExecutor) CopyFrom(ctx context.Context, src string, dst string) error {
	containerName := e.exec.Container.Name
	addr := e.exec.Pod.Status.PodIP
	LoggerFromContext(ctx).Debug("copy from %s on container(%s) in %s pod to %s on local by %s", src, containerName, addr, dst, e.execProtocol())
	return e.exec.CopyFromPod(src, dst)
}

func (e *kubernetesJobExecutor) CopyTo(ctx context.Context, src string, dst string) error {
	containerName := e.exec.Container.Name
	addr := e.exec.Pod.Status.PodIP
	LoggerFromContext(ctx).Debug("copy from %s on local to %s on container(%s) in %s pod by %s", src, dst, containerName, addr, e.execProtocol())
	return e.exec.CopyToPod(src, dst)
}

func (e *kubernetesJobExecutor) Container() corev1.Container {
	return e.exec.Container
}

func (e *kubernetesJobExecutor) Pod() *corev1.Pod {
	return e.exec.Pod
}

type localJob struct {
	rootDir          string
	preInitContainer corev1.Container
	preInitCallback  PreInitCallback
	mountCallback    func(context.Context, JobExecutor, bool) error
	job              *batchv1.Job
}

func newLocalJob(rootDir string, job *batchv1.Job) *localJob {
	return &localJob{
		rootDir:       rootDir,
		job:           job,
		mountCallback: defaultMountCallback,
	}
}

func (j *localJob) Spec() batchv1.JobSpec {
	return j.job.Spec
}

func (j *localJob) PreInit(c TestJobContainer, cb PreInitCallback) {
	j.preInitContainer = c.Container
	j.preInitCallback = cb
}

func (j *localJob) Mount(cb func(context.Context, JobExecutor, bool) error) {
	j.mountCallback = cb
}

func (j *localJob) RunWithExecutionHandler(ctx context.Context, handler func([]JobExecutor) error) error {
	preInitNameToPath := map[string]string{}
	if j.preInitCallback != nil {
		j.preInitCallback(ctx, &localJobExecutor{
			rootDir:   j.rootDir,
			container: j.preInitContainer,
		})
		for _, vm := range j.preInitContainer.VolumeMounts {
			preInitNameToPath[vm.Name] = filepath.Join(j.rootDir, vm.MountPath)
		}
	}
	execs := make([]JobExecutor, 0, len(j.job.Spec.Template.Spec.Containers))
	for _, container := range j.job.Spec.Template.Spec.Containers {
		if err := os.MkdirAll(filepath.Join(j.rootDir, container.WorkingDir), 0755); err != nil {
			return err
		}
		e := &localJobExecutor{
			rootDir:   j.rootDir,
			container: container,
		}
		if err := j.mountCallback(ctx, e, false); err != nil {
			return err
		}
		execs = append(execs, e)
	}
	return handler(execs)
}

type localJobExecutor struct {
	rootDir   string
	container corev1.Container
}

func (e *localJobExecutor) cmd(cmdarr []string) (*exec.Cmd, error) {
	var cmd *exec.Cmd
	if len(cmdarr) == 1 {
		cmd = exec.Command(cmdarr[0])
	} else {
		cmd = exec.Command(cmdarr[0], cmdarr[1:]...)
	}
	for _, env := range e.container.Env {
		if env.Value == "" {
			continue
		}
		cmd.Env = append(cmd.Env, fmt.Sprintf("%s=%s", env.Name, env.Value))
	}
	cmd.Dir = filepath.Join(e.rootDir, e.container.WorkingDir)
	return cmd, nil
}

func (e *localJobExecutor) PrepareCommand(cmdarr []string) ([]byte, error) {
	filteredCmd := []string{}
	for _, c := range cmdarr {
		if strings.HasPrefix(c, "/") {
			filteredCmd = append(filteredCmd, e.rootDir+c)
		} else {
			filteredCmd = append(filteredCmd, c)
		}
	}
	cmd, err := e.cmd([]string{"sh", "-c", strings.Join(filteredCmd, " ")})
	if err != nil {
		return nil, err
	}
	return cmd.CombinedOutput()
}

func (e *localJobExecutor) Output(_ context.Context) ([]byte, error) {
	cmdarr := append(e.container.Command, e.container.Args...)
	if len(cmdarr) == 0 {
		return nil, fmt.Errorf("kubetest: invalid command. command is empty")
	}
	cmd, err := e.cmd(cmdarr)
	if err != nil {
		return nil, err
	}
	return cmd.CombinedOutput()
}

func (e *localJobExecutor) ExecAsync(_ context.Context) {
	cmdarr := append(e.container.Command, e.container.Args...)
	if len(cmdarr) == 0 {
		return
	}
	cmd, err := e.cmd(cmdarr)
	if err != nil {
		return
	}
	go func() {
		_ = cmd.Run()
	}()
}

func (e *localJobExecutor) TerminationLog(_ context.Context, _ string) error {
	return nil
}

func (e *localJobExecutor) Stop(_ context.Context) error {
	return nil
}

func (e *localJobExecutor) CopyFrom(ctx context.Context, src string, dst string) error {
	src = filepath.Join(e.rootDir, src)
	if filepath.Base(src) != filepath.Base(dst) {
		dst = filepath.Join(dst, filepath.Base(src))
	}
	if err := os.MkdirAll(filepath.Dir(dst), 0755); err != nil {
		return err
	}
	LoggerFromContext(ctx).Debug("copy from %s on local to %s on local", src, dst)
	return localCopy(src, dst)
}

func (e *localJobExecutor) CopyTo(ctx context.Context, src string, dst string) error {
	dst = filepath.Join(e.rootDir, dst)
	if filepath.Base(src) != filepath.Base(dst) {
		dst = filepath.Join(dst, filepath.Base(src))
	}
	if err := os.MkdirAll(filepath.Dir(dst), 0755); err != nil {
		return err
	}
	LoggerFromContext(ctx).Debug("copy from %s on local to %s on local", src, dst)
	return localCopy(src, dst)
}

func (e *localJobExecutor) Container() corev1.Container {
	return e.container
}

func (e *localJobExecutor) Pod() *corev1.Pod {
	return &corev1.Pod{}
}

type dryRunJob struct {
	job *batchv1.Job
}

func (j *dryRunJob) Spec() batchv1.JobSpec {
	return j.job.Spec
}

func (j *dryRunJob) PreInit(c TestJobContainer, cb PreInitCallback)         {}
func (j *dryRunJob) Mount(_ func(context.Context, JobExecutor, bool) error) {}

func (j *dryRunJob) RunWithExecutionHandler(ctx context.Context, handler func([]JobExecutor) error) error {
	execs := make([]JobExecutor, 0, len(j.job.Spec.Template.Spec.Containers))
	for _, container := range j.job.Spec.Template.Spec.Containers {
		execs = append(execs, &dryRunJobExecutor{
			container: container,
		})
	}
	return handler(execs)
}

type dryRunJobExecutor struct {
	container corev1.Container
}

func (e *dryRunJobExecutor) PrepareCommand(cmd []string) ([]byte, error) {
	return nil, nil
}

func (e *dryRunJobExecutor) Output(_ context.Context) ([]byte, error) {
	return []byte("( dry running .... )"), nil
}

func (e *dryRunJobExecutor) ExecAsync(_ context.Context)                      {}
func (e *dryRunJobExecutor) TerminationLog(_ context.Context, _ string) error { return nil }
func (e *dryRunJobExecutor) Stop(_ context.Context) error                     { return nil }
func (e *dryRunJobExecutor) CopyFrom(ctx context.Context, src string, dst string) error {
	LoggerFromContext(ctx).Debug("copy from %s on container to %s on local", src, dst)
	return nil
}

func (e *dryRunJobExecutor) CopyTo(ctx context.Context, src string, dst string) error {
	LoggerFromContext(ctx).Debug("copy from %s on local to %s on container", src, dst)
	return nil
}

func (e *dryRunJobExecutor) Container() corev1.Container {
	return e.container
}

func (e *dryRunJobExecutor) Pod() *corev1.Pod {
	return &corev1.Pod{}
}
